<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="3.7.3">Jekyll</generator><link href="http://localhost:4000/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/" rel="alternate" type="text/html" /><updated>2018-03-04T12:32:50+09:00</updated><id>http://localhost:4000/</id><title type="html">北大IT</title><subtitle></subtitle><entry><title type="html">Softmax With Cross Entropy Layer</title><link href="http://localhost:4000/2018/03/03/SoftmaxWithCrossEntropy.html" rel="alternate" type="text/html" title="Softmax With Cross Entropy Layer" /><published>2018-03-03T00:00:00+09:00</published><updated>2018-03-03T00:00:00+09:00</updated><id>http://localhost:4000/2018/03/03/SoftmaxWithCrossEntropy</id><content type="html" xml:base="http://localhost:4000/2018/03/03/SoftmaxWithCrossEntropy.html">&lt;h2 id=&quot;model-structure&quot;&gt;Model Structure&lt;/h2&gt;
&lt;p&gt;&lt;img src=&quot;https://huitclub.github.io/images/softmax.jpg&quot; alt=&quot;Figure1&quot; title=&quot;softmax&quot; /&gt;&lt;/p&gt;

&lt;p&gt;　Softmax関数は多クラス分類問題に使用される。最終層の出力を受け取り、各クラス&lt;script type=&quot;math/tex&quot;&gt;C_k&lt;/script&gt;について入力&lt;script type=&quot;math/tex&quot;&gt;\boldsymbol{x}&lt;/script&gt;が与えられた下での条件付き確率&lt;script type=&quot;math/tex&quot;&gt;y_k = P\left(C_k \mid  \boldsymbol{x} \right)&lt;/script&gt;を計算する。&lt;br /&gt;
　誤差関数には交差エントロピー誤差(cross entropy error)を用いる。交差エントロピーではone-hot表現で与えられる教師データ&lt;script type=&quot;math/tex&quot;&gt;\boldsymbol{t} = (t_k)&lt;/script&gt;を用いて、誤差を計算する。&lt;/p&gt;

&lt;h2 id=&quot;why-use-softmax&quot;&gt;Why use softmax?&lt;/h2&gt;
&lt;p&gt;　多クラス分類では、マルチヌーイ分布(multinoulli distribution)から得られる確率：&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\begin{equation}
P\left(y \mid  \boldsymbol{x} \right) =
\prod_{k=1}^{K} \left( P \left(C_k \mid  \boldsymbol{x} \right) \right)^{t_k}
= \prod_{k=1}^{K-1} \left( P \left(C_k \mid  \boldsymbol{x} \right) \right)^{t_k} \left( P \left(C_K \mid  \boldsymbol{x} \right) \right)^{1 - \sum_{k=1}^{K-1} t_k} = P \left(C_K \mid  \boldsymbol{x} \right) e^{\sum_{k=1}^{K} t_k u_k} \tag{1}
\end{equation}&lt;/script&gt;

&lt;p&gt;を考える。&lt;/p&gt;

&lt;p&gt;ただし、&lt;script type=&quot;math/tex&quot;&gt;u_k&lt;/script&gt;は対数オッズ比：&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\begin{equation}
u_k= \log \dfrac{P \left(C_k \mid  \boldsymbol{x} \right)}{P \left(C_K \mid  \boldsymbol{x} \right)}
\end{equation} \tag{2}&lt;/script&gt;

&lt;p&gt;　この時、&lt;script type=&quot;math/tex&quot;&gt;P\left(y \mid  \boldsymbol{x} \right)&lt;/script&gt;は教師データ&lt;script type=&quot;math/tex&quot;&gt;\boldsymbol{t}=\left(0 \dots 1_{k'} \dots 0 \right)^{\top}&lt;/script&gt;によって与えられる確率&lt;script type=&quot;math/tex&quot;&gt;P \left(C_{k'} \mid  \boldsymbol{x} \right)&lt;/script&gt;を示す。理由は以下の通り。&lt;/p&gt;

&lt;p&gt;まず、式(1)の最後の式における右肩は：&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\begin{equation}
t_k u_k = \delta_{kk'} \log \dfrac{P \left(C_{k'} \mid  \boldsymbol{x} \right)}{P \left(C_K \mid  \boldsymbol{x} \right)}
\end{equation}
（ただし、 \delta_{kk'} はクロネッカーのデルタ）&lt;/script&gt;

&lt;p&gt;より、&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\begin{equation}
\sum_{k=1}^{K} t_k u_k = \log \dfrac{P \left(C_{k'} \mid  \boldsymbol{x} \right)}{P \left(C_K \mid  \boldsymbol{x} \right)}
\end{equation}&lt;/script&gt;

&lt;p&gt;よって、式(1)の最後の式は&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\begin{equation}
P \left(C_K \mid  \boldsymbol{x} \right) e^{\sum_{k=1}^{K} t_k u_k} = P \left(C_K \mid  \boldsymbol{x} \right) e^{\log \frac{P \left(C_{k'} \mid  \boldsymbol{x} \right)}{P \left(C_K \mid  \boldsymbol{x} \right)}} = P \left(C_{k'} \mid  \boldsymbol{x} \right)
\end{equation}&lt;/script&gt;

&lt;p&gt;と、確かに確率&lt;script type=&quot;math/tex&quot;&gt;P \left(C_{k'} \mid  \boldsymbol{x} \right)&lt;/script&gt;を示していることがわかる。&lt;br /&gt;
&lt;br /&gt;
　更に、対数オッズ比(2)について：
&lt;script type=&quot;math/tex&quot;&gt;(2) \Leftrightarrow P \left(C_K \mid  \boldsymbol{x} \right)e^{u_k} = P \left(C_k \mid \boldsymbol{x} \right) \tag{2'}&lt;/script&gt;&lt;/p&gt;

&lt;p&gt;両辺で&lt;script type=&quot;math/tex&quot;&gt;k&lt;/script&gt;について和を取ると、全確率の法則から：&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\sum_{k=1}^{K} P \left(C_K \mid  \boldsymbol{x} \right)e^{u_k} = 1
\Rightarrow P \left(C_K \mid  \boldsymbol{x} \right) = \dfrac{1}{\sum_{k=1}^{K} e^{u_k}}&lt;/script&gt;

&lt;p&gt;これを再び対数オッズ比の式(2’)に代入すると、&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;P \left(C_k \mid \boldsymbol{x} \right) = \dfrac{e^{u_k}}{\sum_{j=1}^{K} e^{u_j}}&lt;/script&gt;

&lt;p&gt;これを利用して各クラスの確率を求める関数：&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\rm{softmax}_k \left(\boldsymbol{u} \right) = \dfrac{e^{u_k}}{\sum_{j=1}^{K} e^{u_j}}&lt;/script&gt;

&lt;p&gt;がsoftmax関数である。&lt;/p&gt;

&lt;h2 id=&quot;why-use-cross-entropy-error&quot;&gt;Why use cross entropy error?&lt;/h2&gt;

&lt;p&gt;対数オッズ比を線形関数でモデル化：&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;u_k = \boldsymbol{\theta}_k^{\top} \boldsymbol{x}&lt;/script&gt;

&lt;p&gt;したものを考えれば、マルチヌーイ分布(1)に対し&lt;script type=&quot;math/tex&quot;&gt;N&lt;/script&gt;個の入力&lt;script type=&quot;math/tex&quot;&gt;\boldsymbol{x}_1,\dots,\boldsymbol{x}_n&lt;/script&gt;と教師データ&lt;script type=&quot;math/tex&quot;&gt;\boldsymbol{t}_1,\dots,\boldsymbol{t}_n&lt;/script&gt;を利用して、パラメータ&lt;script type=&quot;math/tex&quot;&gt;\boldsymbol{\theta}&lt;/script&gt;について最尤推定を行うことで、予測の確率分布を真の確率分布に近づけることができる。&lt;br /&gt;
　すなわち、尤度関数：&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;L(\boldsymbol{\theta}) = \prod_{n=1}^{N} \prod_{k=1}^{K} \left( P  \left(C_k \mid  \boldsymbol{x}_n \right) \right)^{t_{nk}}&lt;/script&gt;

&lt;p&gt;を最大化すればよく、これは交差エントロピー：&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;E(\boldsymbol{\theta}) = - \sum_{n=1}^{N} \sum_{k=1}^{K}　t_{nk} \log \left( P  \left(C_k \mid  \boldsymbol{x}_n \right) \right) \tag{3}&lt;/script&gt;

&lt;p&gt;を最小化することと同義である。故に、交差エントロピー誤差が使用されるのである。&lt;/p&gt;

&lt;h3 id=&quot;meaning-of-cross-entropy-error&quot;&gt;Meaning of Cross Entropy Error&lt;/h3&gt;

&lt;p&gt;交差エントロピー誤差は予測の確率分布&lt;script type=&quot;math/tex&quot;&gt;Q(x)&lt;/script&gt;と真の確率分布&lt;script type=&quot;math/tex&quot;&gt;P(x)&lt;/script&gt;との距離を求めている。&lt;br /&gt;
確率分布の平均情報量(Shannon entropy)：&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;H(P) = - \sum_x P(x) \log P(x)&lt;/script&gt;

&lt;p&gt;を利用して、予測の確率分布&lt;script type=&quot;math/tex&quot;&gt;Q(x)&lt;/script&gt;から真の確率分布&lt;script type=&quot;math/tex&quot;&gt;P(x)&lt;/script&gt;への距離（分布の近さ）をKL情報量(Kullback-Leibler divergence)：&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;D_{KL}(P \mid\mid Q) = \sum_{x \sim P (\rm{x})} P(x) \left( \log P(x) - \log Q(x) \right)&lt;/script&gt;

&lt;p&gt;で計算することができる。&lt;/p&gt;

&lt;p&gt;　これは、&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;D_{KL}(P \mid\mid Q) = \sum_{x \sim P (\rm{x})} P(x) \log P(x) - \sum_{x \sim P (\rm{x})} P(x) \log Q(x)&lt;/script&gt;

&lt;p&gt;となるが、第1項は真の確率分布のみで構成されており、パラメータによる変化がないから、KL情報量を最小化することは第2項：&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;H(P,Q) = - \sum_{x \sim P (\rm{x})} P(x) \log Q(x)&lt;/script&gt;

&lt;p&gt;を最小化することと同義である。これが交差エントロピーであり、実際、予測の確率をsoftmaxから得られる予測確率(&lt;script type=&quot;math/tex&quot;&gt;Q(x)=y_k&lt;/script&gt;)、真の確率を教師データ(&lt;script type=&quot;math/tex&quot;&gt;P(x)=t_k&lt;/script&gt;)と見なせば：&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;H(P,Q) = - \sum_{k} t_k \log y_k&lt;/script&gt;

&lt;p&gt;と、(3)式と一致することが確かめられる(&lt;script type=&quot;math/tex&quot;&gt;y_k = P\left(C_k \mid \boldsymbol{x} \right)&lt;/script&gt;であるから)。&lt;/p&gt;

&lt;p&gt;　すなわち、交差エントロピーを最小化することは、KL情報量の下で与えられる2つの確率分布の近さを最小化することと同義である。&lt;/p&gt;

&lt;h2 id=&quot;forward&quot;&gt;Forward&lt;/h2&gt;
&lt;h3 id=&quot;softmax&quot;&gt;Softmax&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;input:&lt;/strong&gt; &lt;script type=&quot;math/tex&quot;&gt;\boldsymbol{u}^{(L)} = \left( u^{(L)}_j \right)&lt;/script&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;formula:&lt;/strong&gt;&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;y_k = \dfrac{\exp(u_k)}{\sum_{j} \exp(u_j)}&lt;/script&gt;

&lt;p&gt;&lt;strong&gt;output:&lt;/strong&gt; &lt;script type=&quot;math/tex&quot;&gt;\boldsymbol{y} = \left( y_k \right)&lt;/script&gt;&lt;/p&gt;

&lt;h3 id=&quot;cross-entropy&quot;&gt;Cross Entropy&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;input:&lt;/strong&gt; &lt;script type=&quot;math/tex&quot;&gt;\boldsymbol{y} = \left( y_k \right), \boldsymbol{t} = \left( t_k \right)&lt;/script&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;formula:&lt;/strong&gt;&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;E = - \sum_k t_k \log y_k&lt;/script&gt;

&lt;p&gt;&lt;strong&gt;output:&lt;/strong&gt; &lt;script type=&quot;math/tex&quot;&gt;E&lt;/script&gt;&lt;/p&gt;

&lt;h2 id=&quot;backward&quot;&gt;Backward&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;input:&lt;/strong&gt; &lt;script type=&quot;math/tex&quot;&gt;\boldsymbol{y} = \left( y_k \right), \boldsymbol{t} = \left( t_k \right)&lt;/script&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;formula:&lt;/strong&gt;&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\dfrac{\partial E}{\partial u_j^{(L)}} = - \sum_k \dfrac{\partial E}{\partial y_k}\dfrac{\partial y_k}{\partial u_j^{(L)}} = - \sum_k \dfrac{t_k}{y_k}(\delta_{kj} y_k - y_j y_k) = - \sum_k t_k (\delta_{kj} - y_j)&lt;/script&gt;

&lt;p&gt;ただし、上の&lt;script type=&quot;math/tex&quot;&gt;\delta_{kj}&lt;/script&gt;はクロネッカーのデルタ。これをまとめると以下になる。&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\delta_j^{(L)} = y_j - t_j&lt;/script&gt;

&lt;p&gt;&lt;strong&gt;output:&lt;/strong&gt; &lt;script type=&quot;math/tex&quot;&gt;\boldsymbol{\delta}^{(L)} = \left( \delta^{(L)}_j \right) = \left( \dfrac{\partial E}{\partial u_j^{(L)}} \right)&lt;/script&gt;&lt;/p&gt;

&lt;h2 id=&quot;tensorflow&quot;&gt;Tensorflow&lt;/h2&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;tensorflow&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;

&lt;span class=&quot;c&quot;&gt;# softmaxの実装&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;logits&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;layers&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dense&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;inputs&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;z&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;c&quot;&gt;# z.shape = (column(i))&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;units&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;K&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;predictions&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;s&quot;&gt;&quot;classes&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;argmax&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;input&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;logits&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;axis&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
    &lt;span class=&quot;s&quot;&gt;&quot;probabilities&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;softmax&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;logits&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;softmax_tensor&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;

&lt;span class=&quot;c&quot;&gt;# cross entropy errorの実装&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;loss&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;losses&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sparse_softmax_cross_entropy&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;labels&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;labels&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;logits&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;logits&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;</content><author><name></name></author><summary type="html">Model Structure</summary></entry><entry><title type="html">Dense Layer / Fully Connected Layer（全結合層）</title><link href="http://localhost:4000/2018/03/02/DenseLayer.html" rel="alternate" type="text/html" title="Dense Layer / Fully Connected Layer（全結合層）" /><published>2018-03-02T00:00:00+09:00</published><updated>2018-03-02T00:00:00+09:00</updated><id>http://localhost:4000/2018/03/02/DenseLayer</id><content type="html" xml:base="http://localhost:4000/2018/03/02/DenseLayer.html">&lt;h2 id=&quot;model-structure&quot;&gt;Model Structure&lt;/h2&gt;
&lt;p&gt;&lt;img src=&quot;https://huitclub.github.io/images/dense.jpg&quot; alt=&quot;Figure1&quot; title=&quot;dense&quot; /&gt;&lt;/p&gt;

&lt;p&gt;　前の層の出力を受け取り、重みとバイアスの計算処理を行い、次の層（活性化関数の層）へ伝播させる。&lt;/p&gt;

&lt;h2 id=&quot;forward&quot;&gt;Forward&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;input:&lt;/strong&gt; &lt;script type=&quot;math/tex&quot;&gt;\boldsymbol{z}^{(l-1)} = \left( z^{(l-1)}_i \right)&lt;/script&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;parameter:&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;weight: &lt;script type=&quot;math/tex&quot;&gt;\boldsymbol{W}^{(l)} = \left( w^{(l)}_{ji} \right)&lt;/script&gt;&lt;/p&gt;

&lt;p&gt;bias: &lt;script type=&quot;math/tex&quot;&gt;\boldsymbol{b}^{(l)} = \left( b^{(l)}_j \right)&lt;/script&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;formula:&lt;/strong&gt;&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\begin{align*}
\boldsymbol{u}^{(l)} = \boldsymbol{W}^{(l)} \boldsymbol{z}^{(l-1)} + \boldsymbol{b}^{(l)}
\\
u^{(l)}_j = \sum_{i} w_{ji}^{(l)} z_{i}^{(l-1)} + b_{j}^{(l)}
\end{align*}&lt;/script&gt;

&lt;p&gt;&lt;strong&gt;output:&lt;/strong&gt; &lt;script type=&quot;math/tex&quot;&gt;\boldsymbol{u}^{(l)} = \left( u^{(l)}_j \right)&lt;/script&gt;&lt;/p&gt;

&lt;h2 id=&quot;backward&quot;&gt;Backward&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;input:&lt;/strong&gt; &lt;script type=&quot;math/tex&quot;&gt;\boldsymbol{\delta}^{(l)} = \left( \delta^{(l)}_j \right)&lt;/script&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;formula:&lt;/strong&gt;&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\begin{array}{c}
\nabla_{\boldsymbol{W}^{(l)}} E = \boldsymbol{\delta}^{(l)} \left( \boldsymbol{z}^{(l-1)} \right)^{\top}
\\
\dfrac{\partial E}{\partial w^{(l)}_{ji}}= \dfrac{\partial E}{\partial u^{(l)}_{j}} \dfrac{\partial u^{(l)}_{j}}{\partial w^{(l)}_{ji}} = \delta^{(l)}_j z^{(l-1)}_i
\\
\nabla_{\boldsymbol{z}^{(l-1)}} E =  \left( \boldsymbol{W}^{(l)} \right)^{\top}
\boldsymbol{\delta}^{(l)}
\\
\dfrac{\partial E}{\partial z^{(l-1)}_{i}} = \sum_{k} \dfrac{\partial E}{\partial u^{(l)}_{k}}\dfrac{\partial u^{(l)}_{k}}{\partial z^{(l-1)}_{i}} = \sum_{k} \delta^{(l)}_j w^{(l-1)}_k
\end{array}&lt;/script&gt;

&lt;p&gt;&lt;strong&gt;output:&lt;/strong&gt; &lt;script type=&quot;math/tex&quot;&gt;\nabla_{\boldsymbol{W}^{(l)}} E =  \left( \dfrac{\partial E}{\partial w^{(l)}_{ji}}\right),  \nabla_{\boldsymbol{z}^{(l-1)}} E = \left( \dfrac{\partial E}{\partial z^{(l-1)}_{i}} \right)&lt;/script&gt;&lt;/p&gt;

&lt;h2 id=&quot;tensorflow&quot;&gt;Tensorflow&lt;/h2&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;tensorflow&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;dense&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;layers&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dense&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;inputs&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;z&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;              &lt;span class=&quot;c&quot;&gt;# z.shape = (column(i))&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;units&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;J&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;               &lt;span class=&quot;c&quot;&gt;# 隠れ層の unit 数(j)の指定&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;activation&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;relu&lt;/span&gt;  &lt;span class=&quot;c&quot;&gt;# activation function の指定&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;# -&amp;gt; shape = (column(j))&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;</content><author><name></name></author><summary type="html">Model Structure</summary></entry><entry><title type="html">Sequence to Sequence Learning with Neural Networks</title><link href="http://localhost:4000/2018/02/27/Seq2Seq.html" rel="alternate" type="text/html" title="Sequence to Sequence Learning with Neural Networks" /><published>2018-02-27T00:00:00+09:00</published><updated>2018-02-27T00:00:00+09:00</updated><id>http://localhost:4000/2018/02/27/Seq2Seq</id><content type="html" xml:base="http://localhost:4000/2018/02/27/Seq2Seq.html">&lt;p&gt;https://arxiv.org/abs/1409.3215&lt;/p&gt;

&lt;h2 id=&quot;1-introduction&quot;&gt;1. Introduction&lt;/h2&gt;
&lt;p&gt;Seq2Seq は入力ベクトルを受け取って異なる次元のベクトルを出力する LSTM の構造であり、
DNNs にとって困難である、可変的な出力を得ることを可能とした。
翻訳の場合、まず 1 つ目の LSTM で入力ベクトル（各単語）を逆順に受け取り、そこから得られ
る文章の意味を表現する固定次元のベクトル(the fixed- dimensional representation &lt;script type=&quot;math/tex&quot;&gt;\boldsymbol{v}&lt;/script&gt; )を用いて、2 つ目
の LSTM で出力する可変長のベクトル（翻訳語の単語の列）を生成する。&lt;/p&gt;

&lt;h2 id=&quot;2-the-model&quot;&gt;2. The Model&lt;/h2&gt;
&lt;p&gt;&lt;img src=&quot;https://huitclub.github.io/images/seq2seq.jpg&quot; alt=&quot;Figure1&quot; title=&quot;Seq2Seq&quot; /&gt;&lt;/p&gt;

&lt;p&gt;基本的な構造は Figure1 の通りだが、以下の 3 点が違う。&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;前半と後半で 2 つの LSTM を使用する。これにより、計算コストを無視できるほど多くのパラ
メータも持たせられる。&lt;/li&gt;
  &lt;li&gt;Deep LSTM の方が Shallow LSTM よりも性能がいいので、4 層の LSTM を使用する。&lt;/li&gt;
  &lt;li&gt;入力ベクトルを逆順にする。&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;3-experiments&quot;&gt;3. Experiments&lt;/h2&gt;

&lt;h3 id=&quot;31-使用するデータ&quot;&gt;3.1 使用するデータ&lt;/h3&gt;
&lt;p&gt;WMT’14 English to French dataset を使用し、16 万単語をソース文章に、8 万単語を翻訳文章に適用
した。除外された単語は全て”&lt;UNK&gt;”というトークンに置き換えた。&lt;/UNK&gt;&lt;/p&gt;

&lt;h3 id=&quot;32-デコード方法&quot;&gt;3.2 デコード方法&lt;/h3&gt;
&lt;p&gt;デコードには beam search decoder を用いて、単語の部分仮説の内、確率の高い数個を残して、他
の可能性を排除するという操作を行った。&lt;/p&gt;

&lt;h3 id=&quot;33-入力ベクトルを逆順に&quot;&gt;3.3 入力ベクトルを逆順に&lt;/h3&gt;
&lt;p&gt;こうすると精度が向上する厳密な理由はわからないが、minimal time lag 問題を解決し、誤差逆伝
播にてインプットとアウトプット間の communication の確立を容易にした。&lt;/p&gt;

&lt;h3 id=&quot;34-詳細設定&quot;&gt;3.4 詳細設定&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;重みの初期値&lt;script type=&quot;math/tex&quot;&gt;\sim \mathcal{U} (−0.08, 0.08)&lt;/script&gt;&lt;/li&gt;
  &lt;li&gt;SGD を使用し、最初の 5epoch は &lt;script type=&quot;math/tex&quot;&gt;\mu=0.7&lt;/script&gt;でそこから 0.5epoch ごとに半減させ、7.5epochs まで学
習させた。&lt;/li&gt;
  &lt;li&gt;128個のバッチを使用し、勾配を128で割った。&lt;/li&gt;
  &lt;li&gt;勾配爆発問題を防ぐために、は勾配を128で割ったものを&lt;script type=&quot;math/tex&quot;&gt;g&lt;/script&gt;とし、&lt;script type=&quot;math/tex&quot;&gt;s = \left\| g\right\| ^2&lt;/script&gt;を計算し、&lt;script type=&quot;math/tex&quot;&gt;s &gt; 5&lt;/script&gt;の時、 &lt;script type=&quot;math/tex&quot;&gt;g = \dfrac{s}{5g}&lt;/script&gt;とする。&lt;/li&gt;
&lt;/ul&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{align*}
  &amp; \phi(x,y) = \phi \left(\sum_{i=1}^n x_ie_i, \sum_{j=1}^n y_je_j \right)
  = \sum_{i=1}^n \sum_{j=1}^n x_i y_j \phi(e_i, e_j) = \\
  &amp; (x_1, \ldots, x_n) \left( \begin{array}{ccc}
      \phi(e_1, e_1) &amp; \cdots &amp; \phi(e_1, e_n) \\
      \vdots &amp; \ddots &amp; \vdots \\
      \phi(e_n, e_1) &amp; \cdots &amp; \phi(e_n, e_n)
    \end{array} \right)
  \left( \begin{array}{c}
      y_1 \\
      \vdots \\
      y_n
    \end{array} \right)
\end{align*} %]]&gt;&lt;/script&gt;

&lt;h3 id=&quot;35-実験結果&quot;&gt;3.5 実験結果&lt;/h3&gt;
&lt;p&gt;BLEU スコアにおいて、長文でも高い精度が得られた。&lt;/p&gt;

&lt;h2 id=&quot;4-related-work&quot;&gt;4. Related Work&lt;/h2&gt;

&lt;h2 id=&quot;5-conclusion&quot;&gt;5. Conclusion&lt;/h2&gt;
&lt;p&gt;この実験で、制限された語彙と問題仮定のない Deep LSTM が、語彙制限のない大規模の標準的な
統計的機械学習モデルを上回ったことを示した。
実験者が驚いた点は 2 つ。
・ 入力ベクトルを逆順に入れることで、精度が飛躍的に向上した点。
・ 長い文章の翻訳も先行研究と違い、逆順にしたことで高い精度が得られた点。&lt;/p&gt;

&lt;h3 id=&quot;references&quot;&gt;References&lt;/h3&gt;
&lt;p&gt;LSTM formulation
[10] A. Graves. Generating sequences with recurrent neural networks. In Arxiv preprint arXiv:1308.0850,
2013.&lt;/p&gt;

&lt;p&gt;Minimal time lag 問題
[17] S. Hochreiter and J. Schmidhuber. LSTM can solve hard long time lag problems. 1997&lt;/p&gt;</content><author><name></name></author><summary type="html">https://arxiv.org/abs/1409.3215</summary></entry><entry><title type="html">17.4.1 일자 아치리눅스 버그 ‘Conflicting files: ca-certificates-utils: /etc/ssl/certs/ca-certificates.crt already exists in filesystem’</title><link href="http://localhost:4000/2017/04/01/archlinux-bug.html" rel="alternate" type="text/html" title="17.4.1 일자 아치리눅스 버그 'Conflicting files: ca-certificates-utils: /etc/ssl/certs/ca-certificates.crt already exists in filesystem'" /><published>2017-04-01T00:00:00+09:00</published><updated>2017-04-01T00:00:00+09:00</updated><id>http://localhost:4000/2017/04/01/archlinux-bug</id><content type="html" xml:base="http://localhost:4000/2017/04/01/archlinux-bug.html">&lt;p&gt;영어 읽을 수 있다면 그냥 여기를 보면 된다.&lt;/p&gt;

&lt;p&gt;https://www.ostechnix.com/fix-conflicting-files-ca-certificates-utils-etcsslcertsca-certificates-crt-already-exists-filesystem-error-arch-linux/&lt;/p&gt;

&lt;p&gt;한글로 보고 싶거나 필요한 것만 보고 싶은 사람들은 여기서 부터 읽으세요.&lt;/p&gt;

&lt;p&gt;현재 아치리눅스 시스템을 업그레이드 하면&lt;/p&gt;

&lt;p&gt;Conflicting files: ca-certificates-utils: /etc/ssl/certs/ca-certificates.crt already exists in filesystem&lt;/p&gt;

&lt;p&gt;라는 말이 뜨면서 업그레이드가 되지 않는다.&lt;/p&gt;

&lt;p&gt;간단한 해결 방법&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-ruby&quot; data-lang=&quot;ruby&quot;&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
2
3
4
5
6
7
8
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;show&lt;/span&gt;
  &lt;span class=&quot;nb&quot;&gt;puts&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;Outputting a very lo-o-o-o-o-o-o-o-o-o-o-o-o-o-o-o-ong lo-o-o-o-o-o-o-o-o-o-o-o-o-o-o-o-ong line&quot;&lt;/span&gt;
  &lt;span class=&quot;vi&quot;&gt;@widget&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;Widget&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;params&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;ss&quot;&gt;:id&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;respond_to&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;do&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;format&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;|&lt;/span&gt;
    &lt;span class=&quot;nb&quot;&gt;format&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;html&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;# show.html.erb&lt;/span&gt;
    &lt;span class=&quot;nb&quot;&gt;format&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;json&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;render&lt;/span&gt; &lt;span class=&quot;ss&quot;&gt;json: &lt;/span&gt;&lt;span class=&quot;vi&quot;&gt;@widget&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;end&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;end&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;ol&gt;
  &lt;li&gt;(sudo) pacman -Syuw&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;w옵션은 download only 이다&lt;/p&gt;

&lt;p&gt;의미는 Sync-refresh-sysupgrade-download only&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;(sudo) rm /etc/ssl/certs/ca-certificates.crt
지운다.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;(sudo) pacman -Su&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;다운 받아놓은 걸로 설치를 한다&lt;/p&gt;</content><author><name></name></author><summary type="html">영어 읽을 수 있다면 그냥 여기를 보면 된다.</summary></entry></feed>